{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = pd.read_excel(\"C://Users//Purva//Desktop//DS Final projects//5. Bank Reviews-Complaints Analysis//BankReviews.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Stars                                            Reviews  \\\n",
       "0 2017-04-10      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1 2017-02-10      5  Matthew Richardson is professional and helpful...   \n",
       "\n",
       "                   BankName  \n",
       "0  Wyndham Capital Mortgage  \n",
       "1  Wyndham Capital Mortgage  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      505 non-null    datetime64[ns]\n",
      " 1   Stars     505 non-null    int64         \n",
      " 2   Reviews   505 non-null    object        \n",
      " 3   BankName  505 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(2)\n",
      "memory usage: 15.9+ KB\n"
     ]
    }
   ],
   "source": [
    "br.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count and percentage of missing values for the columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BankName</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stars</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count  percentage\n",
       "BankName      0         0.0\n",
       "Reviews       0         0.0\n",
       "Stars         0         0.0\n",
       "Date          0         0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking missing values and printing percent of missing values for each columns\n",
    "\n",
    "\n",
    "count = br.isnull().sum().sort_values(ascending = False)\n",
    "percentage = ((br.isnull().sum()/len(br)*100)).sort_values(ascending = False)\n",
    "missing_data = pd.concat([count,percentage],axis =1,\n",
    "keys = ['count','percentage'])\n",
    "\n",
    "\n",
    "print('count and percentage of missing values for the columns:')\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage for default\n",
      "\n",
      "5    81.19\n",
      "1    18.81\n",
      "Name: Stars, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## checking for distribution of default\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print('Percentage for default\\n')\n",
    "print(round(br.Stars.value_counts(normalize = True)*100,2))\n",
    "round(br.Stars.value_counts(normalize = True)*100,2).plot(kind = 'bar')\n",
    "plt.title('percentage distribution by review type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns\n",
    "\n",
    "br.drop(columns = ['Date'],inplace = True)\n",
    "br.drop(columns = ['BankName'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...\n",
       "1      5  Matthew Richardson is professional and helpful..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# this function converts to lower case,remove square brackets,removes no. and punctuations\n",
    "\n",
    "def text_clean_1(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]','',text)\n",
    "    text = re.sub('[%s]' %re.escape(string.punctuation), '',text)\n",
    "    text = re.sub('\\w*\\d\\w*','',text)\n",
    "    return text\n",
    "\n",
    "cleaned1 = lambda x: text_clean_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['cleaned_reviews'] = pd.DataFrame(br.Reviews.apply(cleaned1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>great job wyndham capital each person was prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>matthew richardson is professional and helpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "\n",
       "                                     cleaned_reviews  \n",
       "0  great job wyndham capital each person was prof...  \n",
       "1  matthew richardson is professional and helpful...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply second round of cleaning\n",
    "\n",
    "def text_clean_2(text):\n",
    "    text = re.sub('[''\"\"...]', '',text)\n",
    "    text = re.sub('\\n', '',text)\n",
    "    return(text)\n",
    "\n",
    "cleaned2 = lambda x: text_clean_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>cleaned_reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>great job wyndham capital each person was prof...</td>\n",
       "      <td>great job wyndham capital each person was prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>matthew richardson is professional and helpful...</td>\n",
       "      <td>matthew richardson is professional and helpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>we had a past experience with wyndham mortgage...</td>\n",
       "      <td>we had a past experience with wyndham mortgage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>we have been dealing with brad thomka from the...</td>\n",
       "      <td>we have been dealing with brad thomka from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>i cant express how grateful i am for the suppo...</td>\n",
       "      <td>i cant express how grateful i am for the suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I had the pleasure of working with Wyndham Cap...</td>\n",
       "      <td>i had the pleasure of working with wyndham cap...</td>\n",
       "      <td>i had the pleasure of working with wyndham cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>My experience with Mattison was beyond greatly...</td>\n",
       "      <td>my experience with mattison was beyond greatly...</td>\n",
       "      <td>my experience with mattison was beyond greatly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Patrick answered all my questions by email imm...</td>\n",
       "      <td>patrick answered all my questions by email imm...</td>\n",
       "      <td>patrick answered all my questions by email imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>I loved working with this group of people! The...</td>\n",
       "      <td>i loved working with this group of people they...</td>\n",
       "      <td>i loved working with this group of people they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Great web interface for both the loan applicat...</td>\n",
       "      <td>great web interface for both the loan applicat...</td>\n",
       "      <td>great web interface for both the loan applicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "5      5  I had the pleasure of working with Wyndham Cap...   \n",
       "6      5  My experience with Mattison was beyond greatly...   \n",
       "7      5  Patrick answered all my questions by email imm...   \n",
       "8      5  I loved working with this group of people! The...   \n",
       "9      5  Great web interface for both the loan applicat...   \n",
       "\n",
       "                                     cleaned_reviews  \\\n",
       "0  great job wyndham capital each person was prof...   \n",
       "1  matthew richardson is professional and helpful...   \n",
       "2  we had a past experience with wyndham mortgage...   \n",
       "3  we have been dealing with brad thomka from the...   \n",
       "4  i cant express how grateful i am for the suppo...   \n",
       "5  i had the pleasure of working with wyndham cap...   \n",
       "6  my experience with mattison was beyond greatly...   \n",
       "7  patrick answered all my questions by email imm...   \n",
       "8  i loved working with this group of people they...   \n",
       "9  great web interface for both the loan applicat...   \n",
       "\n",
       "                                 cleaned_reviews_new  \n",
       "0  great job wyndham capital each person was prof...  \n",
       "1  matthew richardson is professional and helpful...  \n",
       "2  we had a past experience with wyndham mortgage...  \n",
       "3  we have been dealing with brad thomka from the...  \n",
       "4  i cant express how grateful i am for the suppo...  \n",
       "5  i had the pleasure of working with wyndham cap...  \n",
       "6  my experience with mattison was beyond greatly...  \n",
       "7  patrick answered all my questions by email imm...  \n",
       "8  i loved working with this group of people they...  \n",
       "9  great web interface for both the loan applicat...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br['cleaned_reviews_new'] = pd.DataFrame(br.cleaned_reviews.apply(cleaned2))\n",
    "\n",
    "br.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization using re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>cleaned_reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>great job wyndham capital each person was prof...</td>\n",
       "      <td>[great, job, wyndham, capital, each, person, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>matthew richardson is professional and helpful...</td>\n",
       "      <td>[matthew, richardson, is, professional, and, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>we had a past experience with wyndham mortgage...</td>\n",
       "      <td>[we, had, a, past, experience, with, wyndham, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>we have been dealing with brad thomka from the...</td>\n",
       "      <td>[we, have, been, dealing, with, brad, thomka, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>i cant express how grateful i am for the suppo...</td>\n",
       "      <td>[i, cant, express, how, grateful, i, am, for, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                                     cleaned_reviews  \\\n",
       "0  great job wyndham capital each person was prof...   \n",
       "1  matthew richardson is professional and helpful...   \n",
       "2  we had a past experience with wyndham mortgage...   \n",
       "3  we have been dealing with brad thomka from the...   \n",
       "4  i cant express how grateful i am for the suppo...   \n",
       "\n",
       "                                 cleaned_reviews_new  \n",
       "0  [great, job, wyndham, capital, each, person, w...  \n",
       "1  [matthew, richardson, is, professional, and, h...  \n",
       "2  [we, had, a, past, experience, with, wyndham, ...  \n",
       "3  [we, have, been, dealing, with, brad, thomka, ...  \n",
       "4  [i, cant, express, how, grateful, i, am, for, ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stopwords are unnecessary words like was, each etc.\n",
    "## Tokenization means breaking text into individual words\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "br['cleaned_reviews_new'] = br['cleaned_reviews_new'].apply(lambda x: tokenize(x))\n",
    "\n",
    "br.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Purva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# NLTK - Natural Language Tool Kit is library to perform analysis on text \n",
    "# Corpus means bag of words \n",
    "#stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    filtered_text=[word for word in tokenized_list if word not in stop]\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['cleaned_reviews_new']=br['cleaned_reviews_new'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>cleaned_reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>great job wyndham capital each person was prof...</td>\n",
       "      <td>[great, job, wyndham, capital, person, profess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>matthew richardson is professional and helpful...</td>\n",
       "      <td>[matthew, richardson, professional, helpful, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "\n",
       "                                     cleaned_reviews  \\\n",
       "0  great job wyndham capital each person was prof...   \n",
       "1  matthew richardson is professional and helpful...   \n",
       "\n",
       "                                 cleaned_reviews_new  \n",
       "0  [great, job, wyndham, capital, person, profess...  \n",
       "1  [matthew, richardson, professional, helpful, h...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization is bring altogether all simmilar kind of words and create a single word out\n",
    "import nltk\n",
    "wn=nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    lemma=[wn.lemmatize(word) for word in text]\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['cleaned_reviews_new']=br['cleaned_reviews_new'].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count of most frequent words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_count={}\n",
    "\n",
    "for sentence in br['cleaned_reviews_new']:\n",
    "    for word in sentence:\n",
    "        \n",
    "        if word not in word_count:\n",
    "            word_count[word]=1\n",
    "            \n",
    "        else:\n",
    "            word_count[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 139,\n",
       " 'job': 25,\n",
       " 'wyndham': 16,\n",
       " 'capital': 12,\n",
       " 'person': 17,\n",
       " 'professional': 71,\n",
       " 'helped': 35,\n",
       " 'u': 207,\n",
       " 'move': 12,\n",
       " 'refinance': 70,\n",
       " 'process': 257,\n",
       " 'smoothly': 15,\n",
       " 'thank': 50,\n",
       " 'matthew': 3,\n",
       " 'richardson': 1,\n",
       " 'helpful': 56,\n",
       " 'find': 19,\n",
       " 'correct': 1,\n",
       " 'product': 14,\n",
       " 'mortgage': 156,\n",
       " 'much': 38,\n",
       " 'excellent': 30,\n",
       " 'service': 112,\n",
       " 'past': 13,\n",
       " 'experience': 115,\n",
       " 'would': 246,\n",
       " 'without': 29,\n",
       " 'question': 108,\n",
       " 'use': 48,\n",
       " 'needed': 29,\n",
       " 'went': 70,\n",
       " 'beyond': 25,\n",
       " 'extra': 19,\n",
       " 'mile': 8,\n",
       " 'right': 28,\n",
       " 'wrong': 7,\n",
       " 'encountered': 7,\n",
       " 'servicer': 3,\n",
       " 'dealing': 16,\n",
       " 'previous': 13,\n",
       " 'loan': 328,\n",
       " 'pulled': 4,\n",
       " 'together': 8,\n",
       " 'found': 16,\n",
       " 'viable': 3,\n",
       " 'option': 31,\n",
       " 'ultimately': 5,\n",
       " 'saved': 7,\n",
       " 'money': 22,\n",
       " 'highly': 64,\n",
       " 'recommend': 156,\n",
       " 'brad': 7,\n",
       " 'thomka': 3,\n",
       " 'team': 114,\n",
       " 'need': 42,\n",
       " 'sincerest': 2,\n",
       " 'thanks': 61,\n",
       " 'ed': 2,\n",
       " 'lind': 1,\n",
       " 'beginning': 32,\n",
       " 'started': 17,\n",
       " 'stressful': 24,\n",
       " 'time': 221,\n",
       " 'help': 40,\n",
       " 'entire': 47,\n",
       " 'turned': 3,\n",
       " 'happy': 37,\n",
       " 'ending': 1,\n",
       " 'indebted': 1,\n",
       " 'lindread': 1,\n",
       " 'le': 18,\n",
       " 'cant': 27,\n",
       " 'express': 9,\n",
       " 'grateful': 4,\n",
       " 'support': 10,\n",
       " 'zach': 2,\n",
       " 'provided': 36,\n",
       " 'family': 32,\n",
       " 'home': 197,\n",
       " 'purchase': 43,\n",
       " 'customer': 78,\n",
       " 'responsiveness': 11,\n",
       " 'demeanor': 4,\n",
       " 'second': 16,\n",
       " 'none': 9,\n",
       " 'thorough': 11,\n",
       " 'took': 51,\n",
       " 'educate': 4,\n",
       " 'along': 16,\n",
       " 'way': 47,\n",
       " 'working': 72,\n",
       " 'pleasure': 34,\n",
       " 'september': 1,\n",
       " 'making': 23,\n",
       " 'columbus': 1,\n",
       " 'oh': 5,\n",
       " 'original': 7,\n",
       " 'conversation': 17,\n",
       " 'officer': 63,\n",
       " 'underwriting': 8,\n",
       " 'closing': 137,\n",
       " 'responsive': 48,\n",
       " 'impressed': 12,\n",
       " 'smooth': 27,\n",
       " 'timely': 21,\n",
       " 'communication': 37,\n",
       " 'given': 7,\n",
       " 'buying': 32,\n",
       " 'selling': 4,\n",
       " 'mattison': 1,\n",
       " 'greatly': 3,\n",
       " 'professionally': 9,\n",
       " 'done': 44,\n",
       " 'really': 31,\n",
       " 'care': 30,\n",
       " 'client': 15,\n",
       " 'stay': 3,\n",
       " 'top': 19,\n",
       " 'everything': 83,\n",
       " 'misunderstanding': 1,\n",
       " 'overall': 10,\n",
       " 'truly': 10,\n",
       " 'bend': 1,\n",
       " 'back': 45,\n",
       " 'wonderful': 14,\n",
       " 'patrick': 6,\n",
       " 'answered': 27,\n",
       " 'email': 84,\n",
       " 'immediately': 11,\n",
       " 'spent': 11,\n",
       " 'lot': 16,\n",
       " 'sure': 51,\n",
       " 'got': 57,\n",
       " 'situation': 15,\n",
       " 'portal': 1,\n",
       " 'extremely': 46,\n",
       " 'easy': 65,\n",
       " 'closed': 68,\n",
       " 'week': 87,\n",
       " 'pleased': 12,\n",
       " 'intend': 1,\n",
       " 'using': 20,\n",
       " 'later': 39,\n",
       " 'loved': 3,\n",
       " 'group': 1,\n",
       " 'people': 25,\n",
       " 'laughed': 2,\n",
       " 'phone': 48,\n",
       " 'always': 86,\n",
       " 'moved': 4,\n",
       " 'quickly': 23,\n",
       " 'possible': 29,\n",
       " 'knowledgeable': 63,\n",
       " 'staff': 16,\n",
       " 'shopping': 4,\n",
       " 'around': 16,\n",
       " 'lender': 93,\n",
       " 'one': 50,\n",
       " 'badmouthed': 1,\n",
       " 'lost': 3,\n",
       " 'business': 49,\n",
       " 'told': 57,\n",
       " 'class': 4,\n",
       " 'say': 27,\n",
       " 'anything': 15,\n",
       " 'negative': 2,\n",
       " 'another': 32,\n",
       " 'company': 102,\n",
       " 'get': 98,\n",
       " 'sell': 9,\n",
       " 'web': 1,\n",
       " 'interface': 1,\n",
       " 'application': 22,\n",
       " 'document': 31,\n",
       " 'upload': 1,\n",
       " 'download': 1,\n",
       " 'feature': 1,\n",
       " 'quick': 37,\n",
       " 'response': 37,\n",
       " 'concern': 12,\n",
       " 'willingness': 1,\n",
       " 'communicate': 10,\n",
       " 'almost': 18,\n",
       " 'exclusively': 1,\n",
       " 'via': 18,\n",
       " 'emailas': 1,\n",
       " 'call': 96,\n",
       " 'werent': 14,\n",
       " 'michelle': 3,\n",
       " 'well': 47,\n",
       " 'first': 78,\n",
       " 'homeowner': 5,\n",
       " 'feel': 31,\n",
       " 'successful': 7,\n",
       " 'definitely': 33,\n",
       " 'friend': 31,\n",
       " 'usten': 1,\n",
       " 'butler': 2,\n",
       " 'brought': 4,\n",
       " 'humanity': 2,\n",
       " 'connection': 1,\n",
       " 'stiff': 1,\n",
       " 'lifeless': 1,\n",
       " 'scary': 3,\n",
       " 'transaction': 15,\n",
       " 'quite': 15,\n",
       " 'possibly': 5,\n",
       " 'largest': 1,\n",
       " 'wife': 25,\n",
       " 'ever': 35,\n",
       " 'make': 63,\n",
       " 'didnt': 39,\n",
       " 'simply': 3,\n",
       " 'want': 32,\n",
       " 'transact': 1,\n",
       " 'faceless': 1,\n",
       " 'institution': 10,\n",
       " 'riding': 1,\n",
       " 'picking': 1,\n",
       " 'house': 47,\n",
       " 'work': 138,\n",
       " 'austen': 4,\n",
       " 'every': 66,\n",
       " 'step': 38,\n",
       " 'true': 9,\n",
       " 'best': 99,\n",
       " 'deal': 32,\n",
       " 'yes': 3,\n",
       " 'thats': 6,\n",
       " 'also': 46,\n",
       " 'starting': 1,\n",
       " 'looking': 42,\n",
       " 'year': 59,\n",
       " 'wanted': 23,\n",
       " 'presence': 1,\n",
       " 'positivity': 1,\n",
       " 'guidance': 5,\n",
       " 'gave': 18,\n",
       " 'confidence': 4,\n",
       " 'take': 13,\n",
       " 'dream': 15,\n",
       " 'made': 117,\n",
       " 'huge': 7,\n",
       " 'difference': 10,\n",
       " 'kid': 1,\n",
       " 'block': 3,\n",
       " 'couldnt': 27,\n",
       " 'happier': 11,\n",
       " 'jay': 1,\n",
       " 'hold': 10,\n",
       " 'there': 1,\n",
       " 'whole': 21,\n",
       " 'know': 53,\n",
       " 'everythings': 1,\n",
       " 'couldve': 2,\n",
       " 'million': 3,\n",
       " 'especially': 4,\n",
       " 'mark': 5,\n",
       " 'taylor': 1,\n",
       " 'even': 52,\n",
       " 'clock': 1,\n",
       " 'mean': 4,\n",
       " 'heart': 6,\n",
       " 'appreciate': 6,\n",
       " 'chaz': 3,\n",
       " 'fantastic': 11,\n",
       " 'throughout': 32,\n",
       " 'lending': 42,\n",
       " 'share': 3,\n",
       " 'challenge': 4,\n",
       " 'underwriter': 4,\n",
       " 'fault': 1,\n",
       " 'chase': 1,\n",
       " 'yet': 11,\n",
       " 'stepped': 3,\n",
       " 'rectify': 4,\n",
       " 'issue': 29,\n",
       " 'glue': 1,\n",
       " 'kept': 33,\n",
       " 'property': 17,\n",
       " 'falling': 1,\n",
       " 'last': 14,\n",
       " 'minute': 18,\n",
       " 'spirit': 1,\n",
       " 'assisted': 3,\n",
       " 'transitioning': 1,\n",
       " 'new': 32,\n",
       " 'better': 26,\n",
       " 'end': 30,\n",
       " 'cannot': 14,\n",
       " 'enough': 19,\n",
       " 'positive': 8,\n",
       " 'thing': 41,\n",
       " 'consummate': 1,\n",
       " 'plan': 5,\n",
       " 'staying': 1,\n",
       " 'touch': 6,\n",
       " 'future': 31,\n",
       " 'opportunity': 7,\n",
       " 'awsome': 1,\n",
       " 'refi': 22,\n",
       " 'explains': 2,\n",
       " 'thoroughly': 6,\n",
       " 'b': 3,\n",
       " 'repeat': 5,\n",
       " 'salesperson': 1,\n",
       " 'pushing': 3,\n",
       " 'cash': 1,\n",
       " 'im': 20,\n",
       " 'heloc': 2,\n",
       " 'specifically': 6,\n",
       " 'hang': 1,\n",
       " 'said': 41,\n",
       " 'quoted': 2,\n",
       " 'rate': 144,\n",
       " 'td': 1,\n",
       " 'bank': 83,\n",
       " 'ridiculous': 3,\n",
       " 'worst': 5,\n",
       " 'like': 39,\n",
       " 'never': 64,\n",
       " 'gone': 4,\n",
       " 'could': 65,\n",
       " 'complete': 12,\n",
       " 'list': 11,\n",
       " 'required': 13,\n",
       " 'day': 79,\n",
       " 'request': 25,\n",
       " 'appraiser': 10,\n",
       " 'hired': 3,\n",
       " 'many': 38,\n",
       " 'mistake': 21,\n",
       " 'send': 20,\n",
       " 'correction': 3,\n",
       " 'go': 42,\n",
       " 'wyndum': 1,\n",
       " 'continue': 6,\n",
       " 'ask': 23,\n",
       " 'copy': 7,\n",
       " 'filed': 2,\n",
       " 'correctly': 2,\n",
       " 'different': 31,\n",
       " 'awful': 2,\n",
       " 'good': 43,\n",
       " 'frustrating': 5,\n",
       " 'constant': 8,\n",
       " 'delay': 9,\n",
       " 'decision': 17,\n",
       " 'changed': 10,\n",
       " 'overwhelmed': 1,\n",
       " 'log': 1,\n",
       " 'rookie': 1,\n",
       " 'related': 4,\n",
       " 'texas': 1,\n",
       " 'law': 3,\n",
       " 'caused': 5,\n",
       " 'additional': 16,\n",
       " 'wait': 7,\n",
       " 'happened': 9,\n",
       " 'courteous': 5,\n",
       " 'sense': 5,\n",
       " 'urgency': 1,\n",
       " 'upfront': 5,\n",
       " 'learn': 1,\n",
       " 'trusted': 10,\n",
       " 'zero': 2,\n",
       " 'point': 17,\n",
       " 'convinced': 1,\n",
       " 'initially': 5,\n",
       " 'sign': 14,\n",
       " 'faith': 7,\n",
       " 'estimate': 11,\n",
       " 'higher': 7,\n",
       " 'plus': 4,\n",
       " 'credit': 44,\n",
       " 'running': 1,\n",
       " 'number': 10,\n",
       " 'lower': 23,\n",
       " 'interest': 31,\n",
       " 'favorable': 1,\n",
       " 'asking': 10,\n",
       " 'charge': 5,\n",
       " 'look': 19,\n",
       " 'word': 12,\n",
       " 'please': 8,\n",
       " 'careful': 2,\n",
       " 'broker': 28,\n",
       " 'friendly': 36,\n",
       " 'assertive': 2,\n",
       " 'paper': 6,\n",
       " 'filled': 3,\n",
       " 'eminent': 2,\n",
       " 'became': 9,\n",
       " 'increasingly': 2,\n",
       " 'difficult': 7,\n",
       " 'reach': 9,\n",
       " 'initiate': 2,\n",
       " 'seemed': 14,\n",
       " 'forward': 17,\n",
       " 'four': 5,\n",
       " 'payoff': 2,\n",
       " 'card': 7,\n",
       " 'worked': 83,\n",
       " 'kory': 21,\n",
       " 'carla': 3,\n",
       " 'nasb': 103,\n",
       " 'superb': 3,\n",
       " 'complicated': 18,\n",
       " 'hung': 8,\n",
       " 'far': 19,\n",
       " 'two': 35,\n",
       " 'cool': 3,\n",
       " 'calm': 9,\n",
       " 'anyone': 71,\n",
       " 'else': 20,\n",
       " 'moving': 5,\n",
       " 'level': 5,\n",
       " 'integrity': 3,\n",
       " 'expert': 4,\n",
       " 'versed': 3,\n",
       " 'va': 32,\n",
       " 'financial': 27,\n",
       " 'impact': 3,\n",
       " 'component': 3,\n",
       " 'change': 14,\n",
       " 'across': 13,\n",
       " 'buyingselling': 3,\n",
       " 'advocated': 3,\n",
       " 'real': 23,\n",
       " 'estate': 5,\n",
       " 'state': 14,\n",
       " 'due': 17,\n",
       " 'ability': 5,\n",
       " 'close': 58,\n",
       " 'high': 10,\n",
       " 'pressure': 4,\n",
       " 'place': 8,\n",
       " 'patiently': 7,\n",
       " 'answer': 39,\n",
       " 'detailed': 6,\n",
       " 'rally': 3,\n",
       " 'expanded': 3,\n",
       " 'stellar': 5,\n",
       " 'handled': 6,\n",
       " 'tried': 8,\n",
       " 'buy': 24,\n",
       " 'antebellum': 6,\n",
       " 'tough': 9,\n",
       " 'comp': 14,\n",
       " 'retirement': 6,\n",
       " 'military': 9,\n",
       " 'income': 10,\n",
       " 'verification': 5,\n",
       " 'five': 12,\n",
       " 'swapping': 3,\n",
       " 'ton': 6,\n",
       " 'contingency': 3,\n",
       " 'mattered': 4,\n",
       " 'aaron': 23,\n",
       " 'weekend': 8,\n",
       " 'market': 10,\n",
       " 'added': 3,\n",
       " 'origination': 6,\n",
       " 'fee': 27,\n",
       " 'pas': 3,\n",
       " '': 918,\n",
       " 'important': 3,\n",
       " 'despite': 16,\n",
       " 'challenging': 7,\n",
       " 'pull': 4,\n",
       " 'stop': 6,\n",
       " 'rule': 6,\n",
       " 'regulation': 6,\n",
       " 'guide': 8,\n",
       " 'believe': 8,\n",
       " 'loansespecially': 3,\n",
       " 'complicate': 3,\n",
       " 'dallas': 25,\n",
       " 'goodlet': 10,\n",
       " 'deserving': 3,\n",
       " 'special': 6,\n",
       " 'come': 16,\n",
       " 'competitor': 5,\n",
       " 'originally': 6,\n",
       " 'called': 50,\n",
       " 'saving': 15,\n",
       " 'thousand': 10,\n",
       " 'current': 17,\n",
       " 'getting': 27,\n",
       " 'act': 3,\n",
       " 'comment': 5,\n",
       " 'begin': 8,\n",
       " 'signing': 4,\n",
       " 'completion': 4,\n",
       " 'leader': 3,\n",
       " 'online': 15,\n",
       " 'satisfied': 11,\n",
       " 'cost': 46,\n",
       " 'applied': 6,\n",
       " 'tree': 18,\n",
       " 'competitive': 11,\n",
       " 'bid': 3,\n",
       " 'several': 41,\n",
       " 'matched': 5,\n",
       " 'slightly': 3,\n",
       " 'beat': 7,\n",
       " 'convincing': 3,\n",
       " 'chose': 14,\n",
       " 'believability': 3,\n",
       " 'sale': 18,\n",
       " 'assuring': 3,\n",
       " 'supportive': 4,\n",
       " 'truthful': 4,\n",
       " 'brent': 11,\n",
       " 'custer': 5,\n",
       " 'delivered': 5,\n",
       " 'price': 6,\n",
       " 'promised': 8,\n",
       " 'completely': 14,\n",
       " 'appreciative': 3,\n",
       " 'kudos': 3,\n",
       " 'jon': 34,\n",
       " 'amazing': 31,\n",
       " 'start': 23,\n",
       " 'offered': 16,\n",
       " 'since': 17,\n",
       " 'away': 9,\n",
       " 'ready': 15,\n",
       " 'stringent': 3,\n",
       " 'potential': 10,\n",
       " 'buyer': 17,\n",
       " 'calling': 9,\n",
       " 'decide': 5,\n",
       " 'preapproval': 11,\n",
       " 'informational': 3,\n",
       " 'within': 27,\n",
       " 'agreement': 3,\n",
       " 'date': 18,\n",
       " 'barrett': 22,\n",
       " 'asset': 6,\n",
       " 'husband': 11,\n",
       " 'simple': 15,\n",
       " 'patient': 27,\n",
       " 'accurate': 10,\n",
       " 'passing': 3,\n",
       " 'jons': 3,\n",
       " 'name': 9,\n",
       " 'incredibly': 6,\n",
       " 'awesome': 12,\n",
       " 'bryant': 15,\n",
       " 'small': 5,\n",
       " 'purchased': 11,\n",
       " 'refinanced': 11,\n",
       " 'discus': 3,\n",
       " 'ive': 13,\n",
       " 'met': 14,\n",
       " 'authenticity': 4,\n",
       " 'knew': 17,\n",
       " 'instantly': 3,\n",
       " 'going': 46,\n",
       " 'hoped': 3,\n",
       " 'jeff': 3,\n",
       " 'exceeded': 11,\n",
       " 'expectation': 13,\n",
       " 'hard': 40,\n",
       " 'recommended': 16,\n",
       " 'adam': 37,\n",
       " 'attention': 9,\n",
       " 'detail': 17,\n",
       " 'weve': 5,\n",
       " 'thru': 7,\n",
       " 'unsure': 3,\n",
       " 'talking': 13,\n",
       " 'confident': 8,\n",
       " 'manner': 13,\n",
       " 'hesitate': 5,\n",
       " 'agai': 1,\n",
       " 'website': 10,\n",
       " 'tedious': 4,\n",
       " 'received': 35,\n",
       " 'offer': 25,\n",
       " 'multiple': 7,\n",
       " 'alex': 57,\n",
       " 'madewell': 6,\n",
       " 'seamless': 8,\n",
       " 'surprise': 8,\n",
       " 'rob': 3,\n",
       " 'still': 17,\n",
       " 'able': 47,\n",
       " 'peter': 15,\n",
       " 'prompt': 10,\n",
       " 'somehow': 3,\n",
       " 'various': 7,\n",
       " 'roadblock': 3,\n",
       " 'came': 30,\n",
       " 'spoke': 24,\n",
       " 'clear': 16,\n",
       " 'ensure': 12,\n",
       " 'taken': 13,\n",
       " 'aspect': 6,\n",
       " 'necessary': 10,\n",
       " 'effective': 4,\n",
       " 'skill': 5,\n",
       " 'personal': 13,\n",
       " 'sending': 4,\n",
       " 'hand': 8,\n",
       " 'written': 4,\n",
       " 'note': 7,\n",
       " 'congratulation': 3,\n",
       " 'everyone': 20,\n",
       " 'servicing': 9,\n",
       " 'socalled': 3,\n",
       " 'disaster': 3,\n",
       " 'set': 8,\n",
       " 'automatic': 6,\n",
       " 'payment': 28,\n",
       " 'clunky': 3,\n",
       " 'unlike': 9,\n",
       " 'intuitive': 3,\n",
       " 'provide': 12,\n",
       " 'confirmation': 3,\n",
       " 'entry': 3,\n",
       " 'month': 25,\n",
       " 'automatically': 6,\n",
       " 'debited': 9,\n",
       " 'external': 3,\n",
       " 'account': 15,\n",
       " 'scheduled': 5,\n",
       " 'however': 19,\n",
       " 'escrow': 15,\n",
       " 'amount': 22,\n",
       " 'old': 7,\n",
       " 'sent': 31,\n",
       " 'deficiency': 6,\n",
       " 'letter': 16,\n",
       " 'balance': 9,\n",
       " 'used': 21,\n",
       " 'debit': 3,\n",
       " 'counseling': 6,\n",
       " 'telling': 8,\n",
       " 'apply': 6,\n",
       " 'late': 11,\n",
       " 'double': 3,\n",
       " 'suggested': 6,\n",
       " 'department': 9,\n",
       " 'representative': 5,\n",
       " 'error': 12,\n",
       " 'adjusted': 3,\n",
       " 'showing': 4,\n",
       " 'total': 12,\n",
       " 'voice': 3,\n",
       " 'mail': 5,\n",
       " 'message': 8,\n",
       " 'span': 3,\n",
       " 'nasbs': 9,\n",
       " 'default': 6,\n",
       " 'woman': 4,\n",
       " 'rude': 7,\n",
       " 'showed': 6,\n",
       " 'record': 8,\n",
       " 'earlier': 15,\n",
       " 'problem': 34,\n",
       " 'agent': 13,\n",
       " 'man': 7,\n",
       " 'show': 6,\n",
       " 'system': 8,\n",
       " 'adjust': 3,\n",
       " 'experienced': 11,\n",
       " 'incompetence': 3,\n",
       " 'instructed': 5,\n",
       " 'capable': 3,\n",
       " 'actually': 4,\n",
       " 'performing': 3,\n",
       " 'veteran': 9,\n",
       " 'miserable': 3,\n",
       " 'screwed': 3,\n",
       " 'imaginable': 5,\n",
       " 'accepted': 4,\n",
       " 'responsibility': 3,\n",
       " 'wouldnt': 12,\n",
       " 'doghouse': 3,\n",
       " 'purchasing': 8,\n",
       " 'committed': 10,\n",
       " 'communicated': 8,\n",
       " 'questioned': 10,\n",
       " 'item': 10,\n",
       " 'settling': 5,\n",
       " 'lock': 15,\n",
       " 'expired': 11,\n",
       " 'idea': 6,\n",
       " 'unless': 6,\n",
       " 'contacted': 26,\n",
       " 'steve': 25,\n",
       " 'poor': 32,\n",
       " 'mr': 28,\n",
       " 'kang': 3,\n",
       " 'appraise': 5,\n",
       " 'appraising': 3,\n",
       " 'causing': 9,\n",
       " 'disorganized': 6,\n",
       " 'twice': 9,\n",
       " 'picture': 6,\n",
       " 'forgot': 5,\n",
       " 'notification': 5,\n",
       " 'actual': 8,\n",
       " 'settlement': 5,\n",
       " 'sweet': 6,\n",
       " 'competent': 5,\n",
       " 'notary': 10,\n",
       " 'goodness': 5,\n",
       " 'already': 14,\n",
       " 'refinancing': 30,\n",
       " 'steer': 6,\n",
       " 'nick': 6,\n",
       " 'ok': 9,\n",
       " 'fro': 3,\n",
       " 'must': 5,\n",
       " 'understood': 12,\n",
       " 'heard': 11,\n",
       " 'supervisor': 6,\n",
       " 'emailed': 15,\n",
       " 'busness': 3,\n",
       " 'rep': 19,\n",
       " 'donna': 18,\n",
       " 'respond': 24,\n",
       " 'clearly': 5,\n",
       " 'explained': 17,\n",
       " 'unfold': 3,\n",
       " 'sounded': 3,\n",
       " 'count': 3,\n",
       " 'single': 7,\n",
       " 'promise': 20,\n",
       " 'assurance': 7,\n",
       " 'something': 9,\n",
       " 'completed': 18,\n",
       " 'wished': 3,\n",
       " 'violated': 3,\n",
       " 'example': 3,\n",
       " 'traveling': 3,\n",
       " 'country': 4,\n",
       " 'departure': 3,\n",
       " 'happen': 10,\n",
       " 'documentation': 20,\n",
       " 'hour': 22,\n",
       " 'depending': 3,\n",
       " 'occasion': 5,\n",
       " 'assure': 4,\n",
       " 'asked': 28,\n",
       " 'tell': 8,\n",
       " 'pattern': 4,\n",
       " 'recured': 3,\n",
       " 'doesnt': 3,\n",
       " 'incompetent': 3,\n",
       " 'complained': 6,\n",
       " 'wasnt': 15,\n",
       " 'complaint': 5,\n",
       " 'justified': 3,\n",
       " 'sorry': 5,\n",
       " 'unable': 5,\n",
       " 'unwilling': 3,\n",
       " 'broken': 3,\n",
       " 'finally': 12,\n",
       " 'initial': 16,\n",
       " 'imagine': 4,\n",
       " 'long': 9,\n",
       " 'responded': 13,\n",
       " 'hadnt': 3,\n",
       " 'pushed': 4,\n",
       " 'treat': 5,\n",
       " 'disrespect': 3,\n",
       " 'someone': 24,\n",
       " 'owned': 4,\n",
       " 'life': 11,\n",
       " 'honestly': 15,\n",
       " 'owe': 3,\n",
       " 'respectful': 5,\n",
       " 'id': 14,\n",
       " 'star': 19,\n",
       " 'registering': 3,\n",
       " 'site': 4,\n",
       " 'unprofessional': 7,\n",
       " 'disturbing': 3,\n",
       " 'write': 3,\n",
       " 'review': 19,\n",
       " 'prevent': 3,\n",
       " 'north': 12,\n",
       " 'american': 9,\n",
       " 'standard': 4,\n",
       " 'minimal': 5,\n",
       " 'w': 3,\n",
       " 'bob': 12,\n",
       " 'g': 5,\n",
       " 'ran': 4,\n",
       " 'check': 23,\n",
       " 'knowledge': 17,\n",
       " 'consent': 3,\n",
       " 'agreed': 7,\n",
       " 'weeksit': 3,\n",
       " 'paperwork': 11,\n",
       " 'household': 4,\n",
       " 'unpacked': 3,\n",
       " 'power': 5,\n",
       " 'attorney': 9,\n",
       " 'fly': 3,\n",
       " 'doc': 10,\n",
       " 'fedex': 3,\n",
       " 'accept': 6,\n",
       " 'driving': 3,\n",
       " 'nc': 4,\n",
       " 'coordinate': 3,\n",
       " 'read': 190,\n",
       " 'horrible': 7,\n",
       " 'plenty': 5,\n",
       " 'etc': 10,\n",
       " 'disappeared': 3,\n",
       " 'failed': 10,\n",
       " 'give': 29,\n",
       " 'firm': 5,\n",
       " 'thankfully': 4,\n",
       " 'sensed': 3,\n",
       " 'local': 15,\n",
       " 'term': 11,\n",
       " 'low': 8,\n",
       " 'fact': 17,\n",
       " 'round': 6,\n",
       " 'thought': 14,\n",
       " 'select': 6,\n",
       " 'talked': 11,\n",
       " 'directly': 4,\n",
       " 'saying': 13,\n",
       " 'contract': 11,\n",
       " 'signed': 4,\n",
       " 'tomorrow': 3,\n",
       " 'exact': 3,\n",
       " 'parameter': 3,\n",
       " 'replied': 3,\n",
       " 'selected': 4,\n",
       " 'locked': 6,\n",
       " 'following': 4,\n",
       " 'continued': 5,\n",
       " 'receive': 16,\n",
       " 'proceed': 3,\n",
       " 'let': 11,\n",
       " 'january': 3,\n",
       " 'february': 3,\n",
       " 'guess': 3,\n",
       " 'missed': 6,\n",
       " 'boat': 3,\n",
       " 'fall': 4,\n",
       " 'deaf': 3,\n",
       " 'ear': 3,\n",
       " 'though': 6,\n",
       " 'pretty': 8,\n",
       " 'near': 3,\n",
       " 'bunch': 4,\n",
       " 'consultant': 8,\n",
       " 'fixed': 4,\n",
       " 'mentioned': 7,\n",
       " 'exp': 1,\n",
       " 'considerate': 1,\n",
       " 'goal': 4,\n",
       " 'helping': 15,\n",
       " 'achieve': 5,\n",
       " 'connect': 1,\n",
       " 'mary': 2,\n",
       " 'connolly': 1,\n",
       " 'upper': 1,\n",
       " 'management': 1,\n",
       " 'nothing': 16,\n",
       " 'lady': 1,\n",
       " 'uncomfortable': 1,\n",
       " 'nervous': 3,\n",
       " 'available': 29,\n",
       " 'reliance': 20,\n",
       " 'impossible': 3,\n",
       " 'lately': 1,\n",
       " 'improving': 1,\n",
       " 'score': 7,\n",
       " 'reassurance': 2,\n",
       " 'skeptical': 3,\n",
       " 'devastated': 1,\n",
       " 'felt': 28,\n",
       " 'waste': 5,\n",
       " 'approved': 6,\n",
       " 'arose': 4,\n",
       " 'dad': 1,\n",
       " 'declining': 1,\n",
       " 'health': 1,\n",
       " 'demanded': 1,\n",
       " 'room': 1,\n",
       " 'keep': 9,\n",
       " 'expect': 8,\n",
       " 'soon': 4,\n",
       " 'reassured': 3,\n",
       " 'delighted': 1,\n",
       " 'pat': 1,\n",
       " 'informed': 13,\n",
       " 'eligible': 1,\n",
       " 'walk': 8,\n",
       " 'personally': 8,\n",
       " 'superlative': 1,\n",
       " 'sufficient': 3,\n",
       " 'assumed': 3,\n",
       " 'successfully': 2,\n",
       " 'navigated': 1,\n",
       " 'conclusion': 1,\n",
       " 'proved': 1,\n",
       " 'polite': 4,\n",
       " 'consistently': 3,\n",
       " 'remember': 1,\n",
       " 'dealt': 6,\n",
       " 'returned': 6,\n",
       " 'happily': 1,\n",
       " 'enthusiastically': 1,\n",
       " 'others': 4,\n",
       " 'assistance': 3,\n",
       " 'genna': 1,\n",
       " 'englert': 1,\n",
       " 'fast': 21,\n",
       " 'ritu': 2,\n",
       " 'energetic': 1,\n",
       " 'willing': 7,\n",
       " 'run': 3,\n",
       " 'see': 8,\n",
       " 'vacation': 4,\n",
       " 'middle': 3,\n",
       " 'mention': 1,\n",
       " 'delight': 1,\n",
       " 'processing': 5,\n",
       " 'receptive': 1,\n",
       " 'overcoming': 1,\n",
       " 'obstacle': 4,\n",
       " 'honest': 13,\n",
       " 'dependable': 1,\n",
       " 'federal': 1,\n",
       " 'consuming': 1,\n",
       " 'bit': 2,\n",
       " 'explaining': 9,\n",
       " 'obvious': 1,\n",
       " 'informative': 9,\n",
       " 'tim': 4,\n",
       " 'pope': 2,\n",
       " 'leave': 3,\n",
       " 'comfort': 2,\n",
       " 'steven': 9,\n",
       " 'shatz': 4,\n",
       " 'turn': 4,\n",
       " 'financing': 12,\n",
       " 'little': 15,\n",
       " 'result': 14,\n",
       " 'teddy': 6,\n",
       " 'represents': 2,\n",
       " 'communicative': 3,\n",
       " 'hardworking': 2,\n",
       " 'ferrell': 2,\n",
       " 'binh': 2,\n",
       " 'lai': 2,\n",
       " 'member': 2,\n",
       " 'front': 5,\n",
       " 'kelly': 4,\n",
       " 'patience': 7,\n",
       " 'kindness': 3,\n",
       " 'assisting': 2,\n",
       " 'appreciated': 12,\n",
       " 'rasool': 2,\n",
       " 'cared': 4,\n",
       " 'referring': 3,\n",
       " 'perfectly': 4,\n",
       " 'ownership': 2,\n",
       " 'realistic': 2,\n",
       " 'relief': 2,\n",
       " 'information': 28,\n",
       " 'string': 2,\n",
       " 'robert': 7,\n",
       " 'responding': 4,\n",
       " 'jim': 5,\n",
       " 'heisser': 1,\n",
       " 'case': 4,\n",
       " 'daily': 8,\n",
       " 'talkedi': 1,\n",
       " 'friendand': 1,\n",
       " 'til': 1,\n",
       " 'regarding': 1,\n",
       " 'guy': 20,\n",
       " 'path': 4,\n",
       " 'dont': 17,\n",
       " 'gohe': 1,\n",
       " 'phenomenal': 4,\n",
       " 'locate': 1,\n",
       " 'tirelessly': 4,\n",
       " 'loop': 3,\n",
       " 'everyday': 3,\n",
       " 'consolidate': 2,\n",
       " 'debt': 3,\n",
       " 'submitted': 2,\n",
       " 'decided': 14,\n",
       " 'based': 9,\n",
       " 'table': 3,\n",
       " 'settled': 1,\n",
       " 'fairly': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loan</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>process</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  word_count\n",
       "0                  918\n",
       "1     loan         328\n",
       "2  process         257\n",
       "3    would         246\n",
       "4     time         221"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Converting word_count into the dataframe\n",
    "\n",
    "df=pd.DataFrame(word_count.items(), columns=['word','word_count'])\n",
    "df=df.sort_values('word_count', ascending=False).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Purva\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser=SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_pos(sentence):\n",
    "    sent=analyser.polarity_scores(sentence)\n",
    "    return sent['pos']\n",
    "\n",
    "def sentiment_neg(sentence):\n",
    "    sent=analyser.polarity_scores(sentence)\n",
    "    return sent['neg']\n",
    "\n",
    "def sentiment_neu(sentence):\n",
    "    sent=analyser.polarity_scores(sentence)\n",
    "    return sent['neu']\n",
    "\n",
    "def sentiment_comp(sentence):\n",
    "    sent=analyser.polarity_scores(sentence)\n",
    "    return sent['comp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive']=df['word'].apply(sentiment_pos)\n",
    "df['negative']=df['word'].apply(sentiment_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loan</td>\n",
       "      <td>328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>process</td>\n",
       "      <td>257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "      <td>246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  word_count  positive  negative\n",
       "0                  918       0.0       0.0\n",
       "1     loan         328       0.0       0.0\n",
       "2  process         257       0.0       0.0\n",
       "3    would         246       0.0       0.0\n",
       "4     time         221       0.0       0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8         recommend\n",
       "11            great\n",
       "21             best\n",
       "41             easy\n",
       "48           thanks\n",
       "           ...     \n",
       "2334          allow\n",
       "2337      increased\n",
       "2350    significant\n",
       "2369         shared\n",
       "2371     empathetic\n",
       "Name: word, Length: 284, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.loc[df.positive>0]['word']\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88              hard\n",
       "108          problem\n",
       "117             poor\n",
       "177              pay\n",
       "186        stressful\n",
       "            ...     \n",
       "2285        worrying\n",
       "2306           messy\n",
       "2336    unacceptable\n",
       "2368        paranoid\n",
       "2370            drop\n",
       "Name: word, Length: 148, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.loc[df.negative>0]['word']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASSIFICATION OF REVIEWS \n",
    "br['positive']=br['Reviews'].apply(sentiment_pos)\n",
    "br['negative']=br['Reviews'].apply(sentiment_neg)\n",
    "br['neutral']=br['Reviews'].apply(sentiment_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>cleaned_reviews_new</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>great job wyndham capital each person was prof...</td>\n",
       "      <td>[great, job, wyndham, capital, person, profess...</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>matthew richardson is professional and helpful...</td>\n",
       "      <td>[matthew, richardson, professional, helpful, h...</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>we had a past experience with wyndham mortgage...</td>\n",
       "      <td>[past, experience, wyndham, mortgage, would, w...</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>we have been dealing with brad thomka from the...</td>\n",
       "      <td>[dealing, brad, thomka, beginning, started, st...</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>i cant express how grateful i am for the suppo...</td>\n",
       "      <td>[cant, express, grateful, support, zach, provi...</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                                     cleaned_reviews  \\\n",
       "0  great job wyndham capital each person was prof...   \n",
       "1  matthew richardson is professional and helpful...   \n",
       "2  we had a past experience with wyndham mortgage...   \n",
       "3  we have been dealing with brad thomka from the...   \n",
       "4  i cant express how grateful i am for the suppo...   \n",
       "\n",
       "                                 cleaned_reviews_new  positive  negative  \\\n",
       "0  [great, job, wyndham, capital, person, profess...     0.297     0.000   \n",
       "1  [matthew, richardson, professional, helpful, h...     0.297     0.000   \n",
       "2  [past, experience, wyndham, mortgage, would, w...     0.206     0.000   \n",
       "3  [dealing, brad, thomka, beginning, started, st...     0.226     0.018   \n",
       "4  [cant, express, grateful, support, zach, provi...     0.099     0.040   \n",
       "\n",
       "   neutral  \n",
       "0    0.703  \n",
       "1    0.703  \n",
       "2    0.794  \n",
       "3    0.756  \n",
       "4    0.861  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : 454\n",
      "x_test : 51\n",
      "y_train : 454\n",
      "y_test : 51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Independent_var = br.cleaned_reviews_new\n",
    "Dependent_var = br.Stars\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(Independent_var,Dependent_var,test_size = 0.1,random_state = 111)\n",
    "\n",
    "print('x_train :',len(x_train))\n",
    "print('x_test :',len(x_test))\n",
    "print('y_train :',len(y_train))\n",
    "print('y_test :',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "lr = LogisticRegression(solver = \"lbfgs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-15b2b1ee0a67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Vectorizer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \"\"\"\n\u001b[0;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "model = Pipeline([('Vectorizer',tvec),('classifier',lr)])\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8235294117647058\n",
      "Precision : 0.9369747899159664\n",
      "Recall : 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\",accuracy_score(predictions,y_test))\n",
    "print(\"Precision :\",precision_score(predictions,y_test,average = 'weighted'))\n",
    "print(\"Recall :\",recall_score(predictions,y_test,average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
